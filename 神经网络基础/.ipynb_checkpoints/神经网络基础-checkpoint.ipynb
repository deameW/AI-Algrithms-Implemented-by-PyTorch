{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36417df8",
   "metadata": {},
   "source": [
    "### 多层感知机"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b046e2",
   "metadata": {},
   "source": [
    "#### 使用API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6024ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3411, -0.2115, -0.1651, -0.1120, -0.1301, -0.3345,  0.0500,  0.2462,\n",
       "          0.1398,  0.1693],\n",
       "        [-0.1254, -0.2322, -0.0678, -0.2044, -0.1391, -0.1996,  0.0428,  0.2386,\n",
       "          0.0408,  0.1533]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "X = torch.rand((2,20))\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ed379",
   "metadata": {},
   "source": [
    "#### 自动以模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5978b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20,256)\n",
    "        self.out = nn.Linear(256,10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deb20136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1799, -0.2857, -0.0478, -0.0135, -0.1515, -0.1657, -0.0091,  0.0355,\n",
       "          0.1717, -0.1080],\n",
       "        [-0.2313, -0.2420, -0.1103, -0.0679, -0.0295, -0.2445,  0.1250,  0.1628,\n",
       "          0.1478, -0.1971]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = MLP()\n",
    "net2(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83854f",
   "metadata": {},
   "source": [
    "### nn.Sequential实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dcbb106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2651, -0.3284, -0.0281, -0.1864,  0.0945, -0.1045,  0.1616,  0.0243,\n",
       "         -0.2327, -0.0394],\n",
       "        [ 0.1316, -0.3607, -0.1718, -0.2215, -0.0665, -0.1224,  0.1562,  0.2074,\n",
       "         -0.0109,  0.0133]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for block in args:\n",
    "            self._modules[block] = block\n",
    "            \n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            X=block(X)\n",
    "        return X\n",
    "\n",
    "net3 = MySequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "net3(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6648185a",
   "metadata": {},
   "source": [
    "结论：可以通过`nn.Module`来更灵活的实现nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b27364",
   "metadata": {},
   "source": [
    "### 参数管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b808866f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0098],\n",
       "        [-0.0797]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,1))\n",
    "X = torch.rand((2,4))\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a598d980",
   "metadata": {},
   "source": [
    "#### 访问网络中的weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1ff7588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=1, bias=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7238672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.2357, -0.1297, -0.1293,  0.1118,  0.0302, -0.1980, -0.0048,  0.0384]])),\n",
       "             ('bias', tensor([0.0092]))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].state_dict() # weight & bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78d355de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2357, -0.1297, -0.1293,  0.1118,  0.0302, -0.1980, -0.0048,  0.0384]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87714334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.grad == None #还没做back propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4e9bab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n"
     ]
    }
   ],
   "source": [
    "# 一次性访问所有参数\n",
    "print(*[(name, param.shape)for name, param in net[0].named_parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72551ba0",
   "metadata": {},
   "source": [
    "#### 修改内置初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5eba6150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01) #将这一层的网络参数权重初始化为均值为0，标准差为0.01\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "net.apply(init_normal) #所有net中的layer依次应用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a949c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0025, -0.0140, -0.0081, -0.0206],\n",
       "        [-0.0008,  0.0187, -0.0114,  0.0073],\n",
       "        [-0.0019, -0.0152,  0.0006, -0.0074],\n",
       "        [-0.0010, -0.0044,  0.0143, -0.0015],\n",
       "        [-0.0030,  0.0088,  0.0029, -0.0050],\n",
       "        [ 0.0047, -0.0048, -0.0128,  0.0058],\n",
       "        [-0.0192,  0.0038, -0.0171, -0.0080],\n",
       "        [-0.0069, -0.0043, -0.0043, -0.0042]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb4f33",
   "metadata": {},
   "source": [
    "共享权重<br>\n",
    "创建一个Linear层传入到Sequence中，在不同的位置加入这个层，这两个层的参数是共享的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544a7e0",
   "metadata": {},
   "source": [
    "### 自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5327057e",
   "metadata": {},
   "source": [
    "#### 没有参数的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fd812cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0068,  0.2351],\n",
       "        [-0.0541,  0.2204],\n",
       "        [ 0.0151,  0.1978],\n",
       "        [-0.0299,  0.1647]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造一个没有任何参数的自定义层\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,X):\n",
    "        return X-X.mean()\n",
    "\n",
    "net = nn.Sequential(nn.Linear(8,8),CenteredLayer(),nn.ReLU(),nn.Linear(8,2))\n",
    "X = torch.rand((4,8))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a446d0",
   "metadata": {},
   "source": [
    "#### 带参数的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e6ccf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6890,  0.0131, -1.5291],\n",
       "        [ 1.0957, -3.3585,  1.6728],\n",
       "        [ 0.2971, -1.2093,  1.3378],\n",
       "        [ 1.2908, -0.5028,  1.5309],\n",
       "        [ 0.3560, -1.4394, -0.3915]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造一个没有任何参数的自定义层\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self, in_units, out_units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, out_units))\n",
    "        self.bias = nn.Parameter(torch.randn(out_units,))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        linear = torch.matmul(X,self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)\n",
    "\n",
    "dense = CenteredLayer(5,3)\n",
    "dense.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c679df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7042, 0.0000, 4.5077],\n",
       "        [0.0000, 0.0000, 3.2025]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2,5)\n",
    "dense(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734248f",
   "metadata": {},
   "source": [
    "### 读写文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba923cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3)\n",
    "torch.save(x, 'x-file')\n",
    "\n",
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c0ffd5",
   "metadata": {},
   "source": [
    "### 加载和保存模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa596204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20,256)\n",
    "        self.out = nn.Linear(256,10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "    \n",
    "net2 = MLP()\n",
    "net2(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
