{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31a02fd",
   "metadata": {},
   "source": [
    "<img src=\"../images/alext_net.png\" width = 600 height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881d89f",
   "metadata": {},
   "source": [
    "【CONV1】： 96个11x11的卷积核，步长为4，没有零填充。参数：(11 * 11 * 3 +1) * 96<br>\n",
    "【MAX POOL1】: chuangkoudaxiao 3x3, 步长为2。降低图像尺寸，轻微对抗目标便宜带来的影响。 输出尺寸：(55-3)/2 +1 = 27。参数个数：0<br>\n",
    "【NORM1】:归一化层<br>\n",
    "【CONV2】：96个5x5的卷积核，步长为1，使用零填充p=2. 输出特征图尺寸： 27x27x96<br>\n",
    "【MAX POOL2】：256个5x5的卷积核，步长为1，使用零填充p=2。输出特征图：27x27x256<br>\n",
    "【NORM2】<br>\n",
    "【CONV3,CONV3】:384个3x3卷积核，步长为1，使用零填充p=1. 输出尺寸：13x13x384<br>\n",
    "【CONV5】：256ge 3x3卷积核，步长为1，使用零填充p=1.<br>\n",
    "【Max POOL3】：输出6x6x256<br>\n",
    "【FC6,FC7,FC8】:全连接神经网络分类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40b1db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e56019",
   "metadata": {},
   "source": [
    "### 制作图片数据索引train.txt和test.txt两个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "718d6373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_txt_path = os.path.join(\"catVSdog\",\"train.txt\")\n",
    "train_dir = os.path.join(\"catVSdog\",\"train_data\")\n",
    "valid_txt_path = os.path.join(\"catVSdog\",\"test.txt\")\n",
    "valid_dir = os.path.join(\"catVSdog\",\"test_data\")\n",
    "\n",
    "print(type(train_dir))\n",
    "\n",
    "\n",
    "def gen_txt(txt_path, img_dir):\n",
    "    f = open(txt_path, 'w')\n",
    " \n",
    "    for root, s_dirs, _ in os.walk(img_dir, topdown=True):  # 获取 train文件下各文件夹名称\n",
    "        for sub_dir in s_dirs:\n",
    "            i_dir = os.path.join(root, sub_dir)             # 获取各类的文件夹 绝对路径\n",
    "            img_list = os.listdir(i_dir)                    # 获取类别文件夹下所有png图片的路径\n",
    "            for i in range(len(img_list)):\n",
    "                if not img_list[i].endswith('jpg'):         # 若不是png文件，跳过\n",
    "                    continue\n",
    "                #label = (img_list[i].split('.')[0] == 'cat')? 0 : 1 \n",
    "                label = img_list[i].split('.')[0]\n",
    "                # 将字符类别转为整型类型表示\n",
    "                if label == 'cat':\n",
    "                    label = '0'\n",
    "                else:\n",
    "                    label = '1'\n",
    "                img_path = os.path.join(i_dir, img_list[i])\n",
    "                line = img_path + ' ' + label + '\\n'\n",
    "                f.write(line)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cde8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_txt(train_txt_path,train_dir)\n",
    "gen_txt(valid_txt_path,valid_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5824fb2",
   "metadata": {},
   "source": [
    "### 构建Dataset子类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4da3f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    " \n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt_path, transform = None, target_transform = None):\n",
    "        fh = open(txt_path, 'r')\n",
    "        imgs = []\n",
    "        for line in fh:\n",
    "            line = line.rstrip()\n",
    "            words = line.split()\n",
    "            imgs.append((words[0], int(words[1]))) # 类别转为整型int\n",
    "            self.imgs = imgs \n",
    "            self.transform = transform\n",
    "            self.target_transform = target_transform\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        img = Image.open(fn).convert('RGB') \n",
    "        #img = Image.open(fn)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img) \n",
    "        return img, label\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86336aea",
   "metadata": {},
   "source": [
    "note:transform里边可以实现减均值、除标准差、随机裁剪、旋转、翻转、放射变换等操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda410f",
   "metadata": {},
   "source": [
    "### 加载数据集和数据预处理\n",
    "当Mydataset构建好，剩下的操作就交给DataLoder来加载数据集。在DataLoder中，会触发Mydataset中的getiterm函数读取一张图片的数据和标签，并拼接成一个batch返回，作为模型真正的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f700e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_train= transforms.Compose([\n",
    "    # 随机选转图片\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # 将图片尺寸resize到227x227\n",
    "    transforms.Resize((227,227)),\n",
    "    # 将图片转化为tensor格式\n",
    "    transforms.ToTensor(),\n",
    "    # 正则化\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_test = transforms.Compose([\n",
    "    #将图片尺寸resize到227x227\n",
    "    transforms.Resize((227,227)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    #transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = MyDataset('./catVSdog/train.txt',transform = pipeline_train)\n",
    "test_data = MyDataset('./catVSdog/test.txt',transform = pipeline_test)\n",
    "\n",
    "#train_data 和test_data包含多有的训练与测试数据，调用DataLoader批量加载\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset=test_data, batch_size=32, shuffle=False)\n",
    "# 类别信息也是需要我们给定的\n",
    "classes = ('cat', 'dog') # 对应label=0，label=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e319eb",
   "metadata": {},
   "source": [
    "看一下最终制作的数据集图片和它们对应的标签："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4650e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples = enumerate(trainloader)\n",
    "# batch_idx, (example_data, example_label) = next(examples)\n",
    "# # 批量展示图片\n",
    "# for i in range(4):\n",
    "#     plt.subplot(1, 4, i + 1)\n",
    "#     plt.tight_layout()  #自动调整子图参数，使之填充整个图像区域\n",
    "#     img = example_data[i]\n",
    "#     img = img.numpy() # FloatTensor转为ndarray\n",
    "#     img = np.transpose(img, (1,2,0)) # 把channel那一维放到最后\n",
    "#     img = img * [0.5, 0.5, 0.5] + [0.5, 0.5, 0.5]\n",
    "#     plt.imshow(img)\n",
    "#     plt.title(\"label:{}\".format(example_label[i]))\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69138d32",
   "metadata": {},
   "source": [
    "### 搭建AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84ed3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network model consisting of layers propsed by AlexNet paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2):\n",
    "        \"\"\"\n",
    "        Define and allocate layers for this neural net.\n",
    "        Args:\n",
    "            num_classes (int): number of classes to predict with this model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # input size should be : (b x 3 x 227 x 227)\n",
    "        # The image in the original paper states that width and height are 224 pixels, but\n",
    "        # the dimensions after first convolution layer do not lead to 55 x 55.\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),  # (b x 96 x 55 x 55)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # section 3.3\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 96 x 27 x 27)\n",
    "            nn.Conv2d(96, 256, 5, padding=2),  # (b x 256 x 27 x 27)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 13 x 13)\n",
    "            nn.Conv2d(256, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),  # (b x 256 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6)\n",
    "        )\n",
    "        # classifier is just a name for linear layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=(256 * 6 * 6), out_features=500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=500, out_features=20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=20, out_features=num_classes),\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Pass the input through the net.\n",
    "        Args:\n",
    "            x (Tensor): input tensor\n",
    "        Returns:\n",
    "            output (Tensor): output tensor\n",
    "        \"\"\"\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, 256 * 6 * 6)  # reduce the dimensions for linear layer input\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da781b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建模型，部署gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AlexNet().to(device)\n",
    "#定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f22c9",
   "metadata": {},
   "source": [
    "### 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf1b4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_runner(model, device, trainloader, optimizer, epoch):\n",
    "    #训练模型, 启用 BatchNormalization 和 Dropout, 将BatchNormalization和Dropout置为True\n",
    "    model.train()\n",
    "    total = 0\n",
    "    correct =0.0\n",
    " \n",
    "    #enumerate迭代已加载的数据集,同时获取数据和数据下标\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        #把模型部署到device上\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #初始化梯度\n",
    "        optimizer.zero_grad()\n",
    "        #保存训练结果\n",
    "        outputs = model(inputs)\n",
    "        #计算损失和\n",
    "        #多分类情况通常使用cross_entropy(交叉熵损失函数), 而对于二分类问题, 通常使用sigmod\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        #获取最大概率的预测结果\n",
    "        #dim=1表示返回每一行的最大值对应的列下标\n",
    "        predict = outputs.argmax(dim=1)\n",
    "        total = total + labels.size(0)\n",
    "        correct =correct + (predict == labels).sum().item()\n",
    "        #反向传播\n",
    "        loss.backward()\n",
    "        #更新参数\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            #loss.item()表示当前loss的数值\n",
    "            print(\"Train Epoch{} \\t Loss: {:.6f}, accuracy: {:.6f}%\".format(epoch, loss.item(), 100*(correct/total)))\n",
    "            Loss.append(loss.item())\n",
    "            Accuracy.append(correct/total)\n",
    "    return loss.item(), correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14933a53",
   "metadata": {},
   "source": [
    "### 定义测试过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e306096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_runner(model, device, testloader):\n",
    "    #模型验证, 必须要写, 否则只要有输入数据, 即使不训练, 它也会改变权值\n",
    "    #因为调用eval()将不启用 BatchNormalization 和 Dropout, BatchNormalization和Dropout置为False\n",
    "    model.eval()\n",
    "    #统计模型正确率, 设置初始值\n",
    "    correct = 0.0\n",
    "    test_loss = 0.0\n",
    "    total = 0\n",
    "    #torch.no_grad将不会计算梯度, 也不会进行反向传播\n",
    "    with torch.no_grad():\n",
    "        for data, label in testloader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            output = model(data)\n",
    "            test_loss = test_loss + F.cross_entropy(output, label).item()\n",
    "            predict = output.argmax(dim=1)\n",
    "            #计算正确数量\n",
    "            total = total + label.size(0)\n",
    "            correct = correct + (predict == label).sum().item()\n",
    "        #计算损失值\n",
    "        print(\"test_avarage_loss: {:.6f}, accuracy: {:.6f}%\".format(test_loss/total, 100*(correct/total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a66d9",
   "metadata": {},
   "source": [
    "### 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "562f6033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time 2022-08-19 10:06:18\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 46.00 MiB (GPU 0; 2.00 GiB total capacity; 1.54 GiB already allocated; 0 bytes free; 1.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m,time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m,time\u001b[38;5;241m.\u001b[39mlocaltime(time\u001b[38;5;241m.\u001b[39mtime())))\n\u001b[1;32m----> 8\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     Loss\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     10\u001b[0m     Accuracy\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mtrain_runner\u001b[1;34m(model, device, trainloader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     23\u001b[0m correct \u001b[38;5;241m=\u001b[39mcorrect \u001b[38;5;241m+\u001b[39m (predict \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#反向传播\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#更新参数\u001b[39;00m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mD:\\Users\\QianWu\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Users\\QianWu\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 46.00 MiB (GPU 0; 2.00 GiB total capacity; 1.54 GiB already allocated; 0 bytes free; 1.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#调用\n",
    "epoch = 20\n",
    "Loss = []\n",
    "Accuracy = []\n",
    "for epoch in range(1, epoch+1):\n",
    "    print(\"start_time\",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())))\n",
    "    loss, acc = train_runner(model, device, trainloader, optimizer, epoch)\n",
    "    Loss.append(loss)\n",
    "    Accuracy.append(acc)\n",
    "    test_runner(model, device, testloader)\n",
    "    print(\"end_time: \",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),'\\n')\n",
    " \n",
    "print('Finished Training')\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(Loss)\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(Accuracy)\n",
    "plt.title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c9df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
